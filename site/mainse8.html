<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"  
  "http://www.w3.org/TR/html4/loose.dtd">  
<html > 
<head><title>Results</title> 
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"> 
<meta name="generator" content="TeX4ht (http://www.cse.ohio-state.edu/~gurari/TeX4ht/)"> 
<meta name="originator" content="TeX4ht (http://www.cse.ohio-state.edu/~gurari/TeX4ht/)"> 
<!-- html,index=2,3,next,frames --> 
<meta name="src" content="main.tex"> 
<meta name="date" content="2016-07-29 20:29:00"> 
<link rel="stylesheet" type="text/css" href="main.css"> 
</head><body 
>
   <!--l. 810--><div class="crosslinks"><p class="noindent">[<a 
href="mainse9.html" >next</a>] [<a 
href="mainse7.html" >prev</a>] [<a 
href="mainse7.html#tailmainse7.html" >prev-tail</a>] [<a 
href="#tailmainse8.html">tail</a>] [<a 
href="mainch2.html#mainse8.html" >up</a>] </p></div>
   <h3 class="sectionHead"><span class="titlemark">2.3   </span> <a 
 id="x19-380002.3"></a>Results</h3>
<!--l. 812--><p class="noindent" >
   <h4 class="subsectionHead"><span class="titlemark">2.3.1   </span> <a 
 id="x19-390002.3.1"></a>Assessing the Influence of Thresholding</h4>
<!--l. 814--><p class="noindent" >
   <h5 class="subsubsectionHead"><a 
 id="x19-400002.3.1"></a>Score Distributions</h5>
<!--l. 816--><p class="noindent" >Overall, both strategies to handle empty voxels (CCA and SVI) exhibit decreasing Pearson and Spearman
similarity scores with increasing threshold, and this trend is prevalent whether the thresholding includes
both positive and negative values (<a 
href="https://github.com/vsoch/thesis/blob/master/supplementary/chapter2/supp_figure1A.avi" >Supplementary Video 2.1</a>), or just positive values (<a 
href="https://github.com/vsoch/thesis/blob/master/supplementary/chapter2/supp_figure1B.avi" >Supplementary
Video 2.2</a>). For more highly correlated images, CCA seemed to inflate correlation scores. I
observe that a group of more highly positive correlations present for CCA using positive and
negative values is not present for CCA that includes only positive values. This suggests that
using only positive values to calculate correlation serves to deflate scores (consistent with the
fact that it is restricting the range of values), and using both positive and negative values
inflates overall scores. It is not clear if this would be important for distinguishing contrasts of
different types in the task of image comparison. It could be the case that &#8220;deactivations,&#8221;
if they are non-task related will make two images more similar to one another, but in being
consistent across tasks, will act as noise and decrease accuracy to distinguish different tasks and
contrasts from one another. This finding has been suggested in recent work (see Figure 4) of
Gorgolewski et al. (2015). When comparing CCA with SVI, the group of more highly positive
values is relatively smaller, possibly due to the fact that the CCA reduces the size of the mask
drastically, and the other strategies do not, for both positive and negative and only positive values
(Figure&#x00A0;<a 
href="#x19-400012">2.2<!--tex4ht:ref: fig:22 --></a>).
<!--l. 840--><p class="indent" >   <hr class="figure"><div class="figure" 
>
                                                                                   

                                                                                   
<a 
 id="x19-400012"></a>
                                                                                   

                                                                                   
<div class="center" 
>
<!--l. 841--><p class="noindent" >

<!--l. 842--><p class="noindent" ><img 
src="images/figure22.png" alt="PIC"  
></div>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;2.2: </span><span  
class="content"> The size of the mask across different thresholds for complete case analysis (cca) and
single value imputation (svi).</span></div><!--tex4ht:label?: x19-400012 -->
                                                                                   

                                                                                   
<!--l. 845--><p class="indent" >   </div><hr class="endfigure">
<!--l. 848--><p class="indent" >   <hr class="figure"><div class="figure" 
>
                                                                                   

                                                                                   
<a 
 id="x19-400023"></a>
                                                                                   

                                                                                   
<div class="center" 
>
<!--l. 849--><p class="noindent" >

<!--l. 850--><p class="noindent" ><img 
src="images/figure23.png" alt="PIC"  
></div>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;2.3: </span><span  
class="content"> Accuracy of image contrast classification at varying levels of image thresholding, for
comparison of an unthresholded image against a set of images at each threshold, including positive
and negative values (left) and positive values only (right). Complete case analysis (CCA) with a
Pearson score had a maximum accuracy of 0.984 for a threshold of Z = +/- 1.0 (0.983, 0.985),
outperforming single-value imputation (SVI).</span></div><!--tex4ht:label?: x19-400023 -->
                                                                                   

                                                                                   
<!--l. 853--><p class="indent" >   </div><hr class="endfigure">
   <h5 class="subsubsectionHead"><a 
 id="x19-410002.3.1"></a>Thresholding Effects on Classification Accuracy</h5>
<!--l. 857--><p class="noindent" >When assessing the accuracy of image contrast classification at varying levels of image thresholding, CCA
with Pearson has achieved the highest accuracy, followed by CCA with Spearman for both positive and
negative values, and only positive values (Figure&#x00A0;<a 
href="#x19-400023">2.3<!--tex4ht:ref: fig:23 --></a>).
<!--l. 862--><p class="indent" >   Accuracy peaks at 0.984 for a threshold of Z = +/-1.0 (95% confidence interval, 0.983, 0.985) and at
0.953 for a threshold of Z = 0.0 (no threshold) (0.951, 0.954), a subtle indication that inclusion of positive
and negative values improves accuracy of rankings globally. Interestingly, for image comparisons using
positive and negative values, the maximum accuracy does not occur when comparing unthresholded to
unthresholded images, suggesting that values close to 0 may serve as noise across all images and impede the
classification task. When using a Pearson score for either directionality, a threshold value of Z = +/-3.0 can
be used to ensure minimally 0.90 accuracy in returning images of the same contrast, a threshold
that corresponds with images having approximately only 25% of overlapping voxels within
a standard brain mask (Figure&#x00A0;<a 
href="#x19-400012">2.2<!--tex4ht:ref: fig:22 --></a>A). Investigation of the worst-performing contrast across
folds (working memory task, contrast &#8220;0-back body,&#8221; accuracy = 0.758, standard deviation =
0.429) showed equivalent highest performance using CCA with a Pearson score at a threshold of
Z = +/-1.0 (Figure&#x00A0;<a 
href="#x19-410014">2.4<!--tex4ht:ref: fig:24 --></a>), still much higher than chance (2%). Surprisingly, the global peak
accuracy of 0.902 (95% confidence interval, 0.876, 0.928) occurred for a Spearman score with CCA
using positive values only. Complete accuracy results for combined images across folds are
included in <a 
href="https://github.com/vsoch/thesis/blob/master/supplementary/chapter2/supp_data2_ml_accuracy.csv" >Supplementary Data 2.2</a>, and for the worst performing image in <a 
href="https://github.com/vsoch/thesis/blob/master/supplementary/chapter2/supp_data3_ml_accuracy_TASK07_CON35.csv" >Supplementary Data
2.3</a>.
<!--l. 884--><p class="indent" >   <hr class="figure"><div class="figure" 
>
                                                                                   

                                                                                   
<a 
 id="x19-410014"></a>
                                                                                   

                                                                                   
<div class="center" 
>
<!--l. 885--><p class="noindent" >

<!--l. 886--><p class="noindent" ><img 
src="images/figure24.png" alt="PIC"  
></div>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;2.4: </span><span  
class="content"> Accuracy of image contrast classification at varying levels of thresholding, for the worst
performing image, "0-back body," from the working memory task. Accuracy peaked at a threshold
of Z = +/- 1.0 for complete case analysis with a Pearson score and at a threshold of Z = + 2.0
for complete case analysis with a Spearman score for each of positive and negative values (left) and
positive values only (right).</span></div><!--tex4ht:label?: x19-410014 -->
                                                                                   

                                                                                   
<!--l. 889--><p class="indent" >   </div><hr class="endfigure">
   <h4 class="subsectionHead"><span class="titlemark">2.3.2   </span> <a 
 id="x19-420002.3.2"></a>Image Classification</h4>
<!--l. 893--><p class="noindent" >Across a range of thresholds, very high classification accuracy was achieved between contrasts, consistent
with but substantially better than previous between-subject classification studies (e.g., Poldrack et al.,
2009). Figure&#x00A0;<a 
href="#x19-420015">2.5<!--tex4ht:ref: fig:25 --></a> presents the mean accuracy and standard deviation for each contrast across 500
random folds for the optimally performing threshold (Z = +/- 1.0), direction (positive and
negative), comparison strategy (CCA) and similarity metric (Pearson score). Classification is
consistently accurate to distinguish contrasts between tasks (with 30 contrasts being perfectly
classified across all 500 folds), and classification errors are seen for similar contrasts within the
same task (e.g., working memory contrasts &#8220;0-back body&#8221; vs. &#8220;body,&#8221; (overlapping conditions)
and gambling task contrasts &#8220;punish,&#8221; vs. &#8220;reward.&#8221;) The only misclassification between tasks
occurs for the gambling &#8220;punish - reward&#8221; contrast predicted to be the working memory &#8220;face -
average&#8221; contrast. Interactive confusion matrices to explore the complete result are available
(<a 
href="http://vsoch.github.io/image-comparison-thresholding" >http://vsoch.github.io/image-comparison-thresholding</a>).
<!--l. 911--><p class="indent" >   <hr class="figure"><div class="figure" 
>
                                                                                   

                                                                                   
<a 
 id="x19-420015"></a>
                                                                                   

                                                                                   
<div class="center" 
>
<!--l. 912--><p class="noindent" >

<!--l. 913--><p class="noindent" ><img 
src="images/figure25.png" alt="PIC"  
></div>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;2.5:  </span><span  
class="content">  Mean  accuracy  +/-  1.0  standard  deviation  for  each  contrast  across  500  random
folds  for  the  optimally  performing  threshold  (Z  =  +/-  1.0),  direction  (positive  and  negative),
comparison  strategy  (complete  case  analysis)  and  similarity  metric  (Pearson  score).  Interactive
confusion matrices for all thresholds, comparison strategies, and similarity metrics are available
(<a 
href="http://vsoch.github.io/image-comparison-thresholding" >http://vsoch.github.io/image-comparison-thresholding</a>) <br 
class="newline" /><br 
class="newline" /></span></div><!--tex4ht:label?: x19-420015 -->
                                                                                   

                                                                                   
<!--l. 917--><p class="indent" >   </div><hr class="endfigure">
                                                                                   

                                                                                   
   <!--l. 919--><div class="crosslinks"><p class="noindent">[<a 
href="mainse9.html" >next</a>] [<a 
href="mainse7.html" >prev</a>] [<a 
href="mainse7.html#tailmainse7.html" >prev-tail</a>] [<a 
href="mainse8.html" >front</a>] [<a 
href="mainch2.html#mainse8.html" >up</a>] </p></div>
<!--l. 919--><p class="indent" >   <a 
 id="tailmainse8.html"></a>   
</body></html> 
