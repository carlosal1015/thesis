<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"  
  "http://www.w3.org/TR/html4/loose.dtd">  
<html > 
<head><title>Web Based Tools for Neuroimaging</title> 
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"> 
<meta name="generator" content="TeX4ht (http://www.cse.ohio-state.edu/~gurari/TeX4ht/)"> 
<meta name="originator" content="TeX4ht (http://www.cse.ohio-state.edu/~gurari/TeX4ht/)"> 
<!-- html,index=2,3,next,frames --> 
<meta name="src" content="main.tex"> 
<meta name="date" content="2016-07-29 20:29:00"> 
<link rel="stylesheet" type="text/css" href="main.css"> 
</head><body 
>
   <!--l. 3239--><div class="crosslinks"><p class="noindent">[<a 
href="mainse29.html" >next</a>] [<a 
href="mainse27.html" >prev</a>] [<a 
href="mainse27.html#tailmainse27.html" >prev-tail</a>] [<a 
href="#tailmainse28.html">tail</a>] [<a 
href="mainap3.html#mainse28.html" >up</a>] </p></div>
   <h3 class="sectionHead"><span class="titlemark">C.3   </span> <a 
 id="x44-152000C.3"></a>Web Based Tools for Neuroimaging</h3>
<!--l. 3241--><p class="noindent" >We have reviewed the basic components of developing and deploying web based tools. Technology for
reproducible research means integration of these components, including servers and databases, and high
performance computing, while keeping user experience and proper documentation in mind to produce a
final product that serves as the dissemination of the result. In the modern age, a final product is typically
expected to have searching capabilities, intuitive design and visualization, and integration with cloud
resources.
<!--l. 3250--><p class="noindent" >
   <h4 class="subsectionHead"><span class="titlemark">C.3.1   </span> <a 
 id="x44-153000C.3.1"></a>Visualization</h4>
<!--l. 3252--><p class="noindent" >The sharing a result is almost impossible without showing something meaningful. The reason
for success of the internet as a platform for reading, learning, and everything, is primarily
because of the visual experience that it affords. This means that, while it is often undervalued,
visualization is an important, if not one of the most important, components for a web-based
application. Data visualization for highly dimensional and complex data can help to discover
patterns, generating hypothesis, and develop subsequent models of natural phenomena. The task
of rendering a single statistical brain map in a browser, or a matrix of connectivity data [<span 
class="ec-lmbx-10">?</span>
]http://vsoch.github.io/mybrain/ is no simple thing. Modern javascript libraries such as D3 [<span 
class="ec-lmbx-10">? </span>] can
handle a few thousand objects in the browser before seeing huge detriments to performance,
and a queue technique using canvas [<span 
class="ec-lmbx-10">? </span>] could handle many more values, but renders them
statically.
<!--l. 3266--><p class="noindent" >
   <h5 class="subsubsectionHead"><a 
 id="x44-154000C.3.1"></a>Pybraincompare</h5>
<!--l. 3268--><p class="noindent" >To unite the processing of brain images using python and web visualization, I developed a python module,
pybraincompare [<span 
class="ec-lmbx-10">? </span>], that works as a tool to perform some analysis of interest with a brain image, and then
immediately renders the result in the user&#8217;s local browser. The tool can generate web reports for quality
analysis (QA), scatterplots to compare two brain maps, connectograms, as well as tree data structures to
render ontological relationships (Figure&#x00A0;reffig:54).
                                                                                   

                                                                                   
<!--l. 3276--><p class="indent" >   <hr class="figure"><div class="figure" 
>
                                                                                   

                                                                                   
                                                                                   

                                                                                   
<div class="center" 
>
<!--l. 3277--><p class="noindent" >

<!--l. 3278--><p class="noindent" ><img 
src="images/figure54.png" alt="PIC"  
></div>
<!--l. 3280--><p class="noindent" > <span 
class="ec-lmbx-10">Figure 5.4  </span>The Pybraincompare Python package produces several interactive visualizations for brain
imaging analysis, including an interactive quality analysis report (top left), a scatterplot matrix to compare
two images (top right), an ontology tree (bottom left), and a connectogram for functional MRI (bottom
right).
                                                                                   

                                                                                   
<!--l. 3281--><p class="indent" >   </div><hr class="endfigure">
<!--l. 3283--><p class="indent" >   Importantly, this python package also contains the spatial and semantic methods that have driven the
work of my thesis, allowing for a neuroimaging researcher to deploy the same methods in his or her
pipelines. As an example, pybraincompare is the driver behind the &#8220;image comparison&#8221; feature in
NeuroVault, taking responsibility for both doing the computations, and rendering a search interface
(Figure&#x00A0;<a 
href="#x44-1540012">C.2<!--tex4ht:ref: fig:55 --></a>) as well as pairwise scatterplots to assess the similarity of two images (Figure&#x00A0;<a 
href="#x44-154000C.3.1">C.3.1<!--tex4ht:ref: fig:54 --></a> top
right).
<!--l. 3291--><p class="indent" >   <hr class="figure"><div class="figure" 
>
                                                                                   

                                                                                   
<a 
 id="x44-1540012"></a>
                                                                                   

                                                                                   
<div class="center" 
>
<!--l. 3292--><p class="noindent" >

<!--l. 3293--><p class="noindent" ><img 
src="images/figure55.png" alt="PIC"  
></div>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;C.2: </span><span  
class="content"> The Pybraincompare Python package renders the interactive search interface to power
spatial image comparison in the NeuroVault database.</span></div><!--tex4ht:label?: x44-1540012 -->
                                                                                   

                                                                                   
<!--l. 3296--><p class="indent" >   </div><hr class="endfigure">
<!--l. 3298--><p class="indent" >   Pybraincompare also brings with it functions to generate output using canvas, allowing for the
rendering of over 150K data points in under 3 seconds. The contrast between a canvas rendering that
allows for this number of data points and a D3 rendering that handles a few thousand demonstrates the
trade-off between interactivity and usability. Generation of a visualization must be done in a manner
that is intuitive and transparent to the viewer, and the visualization itself must strike a fine
balance between revealing the data&#8217;s inherent complexity and providing an easily digestible
abstraction.
   <h5 class="subsubsectionHead"><a 
 id="x44-155000C.3.1"></a>Nifti-drop</h5>
<!--l. 3308--><p class="noindent" >The drawback of a tool like pybraincompare is that it requires a server or a local machine. As was
previously noted, the divide between a user&#8217;s computer and the browser is getting fuzzy. Most
user&#8217;s of web applications do not want to spend the time to download software, or even go
through extensive upload processes. This demand for instantaneous function led me to ask the
question if it would be possible to render a complex data such as a brain image directly in a
browser, and this resulted in nifti-drop (<a 
href="http://vsoch.github.io/nifti-drop/" >http://vsoch.github.io/nifti-drop/</a>). First, a nifti file is
a standard data format in neuroimaging [<span 
class="ec-lmbx-10">? </span>]. It can store a 3D brain image, or a 4D brain
image, meaning a 3D image collected over time. The nifti-drop prototype uses modern web
technology, specifically the File Reader web API [<span 
class="ec-lmbx-10">? </span>] to allow for a user to drop one of these files
directly on the browser, and have the image data (the &#8220;brain map&#8221;) and the header information
(meta data about the image) render immediately in the browser. The viewer also supports
dropping an NIDM-Results data structure (Section 4.3.1) to immediately render the Contrast map
and associated points. This project uses JavaScript, HTML5, Bootstrap, along with the web
query language Sparql and FileReader, and putting all of these pieces together was highly
challenging.
<!--l. 3330--><p class="noindent" >
   <h5 class="subsubsectionHead"><a 
 id="x44-156000C.3.1"></a>Brain Browser and Niindex</h5>
<!--l. 3332--><p class="noindent" >As an extension to the nifti-drop, it seemed like a reasonable goal to generate a small application to
equivalently render a local brain map in the browser, but allow for serving of images from the user file system.
Toward this goal, I developed the Brain Browser (<a 
href="https://www.npmjs.com/package/brain-browser" >https://www.npmjs.com/package/brain-browser</a>),
a node-js application [<span 
class="ec-lmbx-10">? </span>]. It then became apparent that this kind of functionality might be
desired for a server, and so I modified the standard File Browser behavior of a server to
immediately render any brain images in a subset of folders, a project that I called niindex
(<a 
href="http://www.vbmis.com/bmi/project/niindex/" >http://www.vbmis.com/bmi/project/niindex/</a>). This string of brain viewers serves as an example for the
kinds of ideas that can better fit servers, local computers, and web sites to host highly complex brain
                                                                                   

                                                                                   
imaging data.
                                                                                   

                                                                                   
   <!--l. 3345--><div class="crosslinks"><p class="noindent">[<a 
href="mainse29.html" >next</a>] [<a 
href="mainse27.html" >prev</a>] [<a 
href="mainse27.html#tailmainse27.html" >prev-tail</a>] [<a 
href="mainse28.html" >front</a>] [<a 
href="mainap3.html#mainse28.html" >up</a>] </p></div>
<!--l. 3345--><p class="indent" >   <a 
 id="tailmainse28.html"></a>    
</body></html> 
